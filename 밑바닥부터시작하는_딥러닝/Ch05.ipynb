{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Ch05_김민지.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EflE2kk9WeKQ",
        "colab_type": "text"
      },
      "source": [
        "# **Chapter 5 오차역전파법**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emp2jnG2WmgJ",
        "colab_type": "text"
      },
      "source": [
        "5.1~5.3은 교재 참고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK--nbkWYIUK",
        "colab_type": "text"
      },
      "source": [
        "## **5.4 단순한 계층 구현하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7Ov9V93X_7g",
        "colab_type": "text"
      },
      "source": [
        "### **5.4.1 곱셈 계층**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVzqDYcQWY-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MulLayer:\n",
        "  def __init__(self):\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "\n",
        "  def forward(self,x,y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    out = x*y\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self,dout):\n",
        "    dx = dout*self.y # x와 y를 바꾼다.\n",
        "    dy = dout*self.x\n",
        "\n",
        "    return dx, dy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl7WYnT6XCbb",
        "colab_type": "text"
      },
      "source": [
        " 곱셈 계층을 구현해보았다.\n",
        "\n",
        "forward()는 순전파, backward()는 역전파를 처리한다. \n",
        "\n",
        "__init__()에서는 인스턴스 변수인 x와 y를 초기화한다. 이 두 변수는 순전파 시의 입력 값을 유지하기 위해 사용한다. \n",
        "\n",
        "forward()에서는 x와 y를 인수로 받아 두 값을 곱하여 반환한다. 반면 backward()에서는 상류에서 넘어온 미분(dout)에 순전파 때의 값을 서로 바꿔 곱한 후 하류로 흘린다. \n",
        "\n",
        "___\n",
        "\n",
        "인스턴스 변수는 클래스 변수와 마찬가지로 클래스 내에 선언한다. 클래스 변수와의 차이점은 인스턴스에 종속되어 인스턴스 생성시 마다 새로운 저장공간을 할당한다는 점이다. 즉 저장공간이 공유되지 않는다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny6rQ0GqWlGJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3cfd8756-0517-477f-95d3-4039db656b6a"
      },
      "source": [
        "# 교재 p.161 그림 5-16의 순전파 구현\n",
        "\n",
        "apple = 100 # 사과 가격\n",
        "apple_num = 2 # 사과의 개수\n",
        "tax = 1.1 # 소비세\n",
        "\n",
        "# 계층들\n",
        "mul_apple_layer = MulLayer()\n",
        "mul_tax_layer = MulLayer()\n",
        "\n",
        "# 순전파\n",
        "apple_price = mul_apple_layer.forward(apple,apple_num)\n",
        "price = mul_tax_layer.forward(apple_price,tax)\n",
        "\n",
        "print(price)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "220.00000000000003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glD0h9wpYr2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6a5fc27f-7e9f-4a95-b667-9d0b2588ace2"
      },
      "source": [
        "# 역전파\n",
        "dprice = 1\n",
        "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
        "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
        "\n",
        "print(dapple, dapple_num, dtax)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2 110.00000000000001 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmB8ZviAZeTo",
        "colab_type": "text"
      },
      "source": [
        "backward()에서 각 변수에 대한 미분을 구했다. backward()가 받는 인수는 순전파의 출력에 대한 미분이다. \n",
        "\n",
        "코드를 실행한 결과는 그림 5-16의 결과와 일치한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSqDrQgjZxCM",
        "colab_type": "text"
      },
      "source": [
        "### **5.4.2 덧셈 계층**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vfk9eWpZQPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AddLayer:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    out = x + y\n",
        "    return out\n",
        "\n",
        "  def backward(self,dout):\n",
        "    dx = dout*1\n",
        "    dy = dout*1\n",
        "    return dx,dy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri7QPpk9aLoa",
        "colab_type": "text"
      },
      "source": [
        "덧셈 계층을 구현했다. 덧셈 계층에서는 초기화가 필요 없어서 __init__()에서 아무 일도 하지 않았다. (pass는 아무것도 하지 말라는 명령임) \n",
        "\n",
        "덧셈 계층의 forward()에서는 입력받은 두 인수 x,y를 더해서 반환한다. \n",
        "\n",
        "backward()에서는 상류에서 내려온 미분을 그대로 하류로 흘린다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCU-YPAGaDjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 교재 pg.163의 그림 5-17 구현\n",
        "\n",
        "apple = 100 # 사과 가격\n",
        "apple_num = 2 # 사과 개수\n",
        "orange = 150 # 오렌지 가격\n",
        "orange_num = 3 # 오렌지 개수\n",
        "tax = 1.1 # 소비세\n",
        "\n",
        "# 계층들\n",
        "mul_apple_layer = MulLayer()\n",
        "mul_orange_layer = MulLayer()\n",
        "add_apple_orange_layer = AddLayer()\n",
        "mul_tax_layer = MulLayer()\n",
        "\n",
        "# 순전파\n",
        "apple_price = mul_apple_layer.forward(apple, apple_num) #(1)\n",
        "orange_price = mul_orange_layer.forward(orange, orange_num) #(2)\n",
        "all_price = add_apple_orange_layer.forward(apple_price,orange_price) #(3)\n",
        "price = mul_tax_layer.forward(all_price,tax) #(4)\n",
        "\n",
        "# 역전파\n",
        "dprice = 1\n",
        "dall_price,dtax = mul_tax_layer.backward(dprice) #(4)\n",
        "dapple_price,dorange_price = add_apple_orange_layer.backward(dall_price) #(3)\n",
        "dorange,dorange_num = mul_orange_layer.backward(dorange_price) #(2)\n",
        "dapple, dapple_num = mul_apple_layer.backward(dapple_price) #(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yha_KEKWdLn5",
        "colab_type": "text"
      },
      "source": [
        "필요한 계층을 만들어 순전파 메서드인 forward()를 적절한 순서로 호출했다. 그런 다음 순전파와 반대 순서로 역전파 메서드인 backward()를 호출해 원하는 미분이 나오게 했다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aawyjOq3cz6x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ed347ef8-74dd-4afc-ac80-42e7456464fc"
      },
      "source": [
        "print(price)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "715.0000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD_YLpg-c7Yf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a9ae5944-5d44-47f2-8627-357d1736b9ce"
      },
      "source": [
        "print(dapple_num, dapple, dorange, dorange_num, dtax)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "110.00000000000001 2.2 3.3000000000000003 165.0 650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxfvDJ1gdzJz",
        "colab_type": "text"
      },
      "source": [
        "코드를 실행한 결과가 그림 5-17의 결과와 일치한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE3FjAYHd5i_",
        "colab_type": "text"
      },
      "source": [
        "## **5.5 활성화 함수 계층 구현하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOpWYoNod_vN",
        "colab_type": "text"
      },
      "source": [
        "### **5.5.1 ReLU 계층**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPZUVbrZggku",
        "colab_type": "text"
      },
      "source": [
        "ReLU는 x가 0을 초과하면 x를, 0 이하이면 0을 출력하는 함수이다. 순전파 때의 입력인 x가 0보다 크면 역전파는 상류의 값을 그대로 하류로 흘리고, 순전파 때 x가 0 이하면 역전파 때는 하류로 신호를 보내지 않는다. (0을 보낸다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e10I6BLbdBpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu:\n",
        "  def __init__(self):\n",
        "    self.mask = None\n",
        "  \n",
        "  def forward(self,x):\n",
        "    self.mask = (x<=0)\n",
        "    out = x.copy()\n",
        "    out[self.mask] = 0\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dout[self.mask] = 0\n",
        "    dx = dout\n",
        "\n",
        "    return dx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2stQn7NvhhUI",
        "colab_type": "text"
      },
      "source": [
        "ReLU 계층을 구현했다. \n",
        "\n",
        "ReLU 클래스는 mask라는 인스턴스 변수를 가진다. mask는 True/False로 구성된 넘파이 배열로, 순전파의 입력인 x의 원소 값이 0 이하인 인덱스는 True, 그 외(0보다 큰 원소)는 False로 유지한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0SAQnM5hN1K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b5da3f76-2521-4e11-aa43-7d25665972ea"
      },
      "source": [
        "import numpy as np\n",
        "x = np.array([[1.0,-0.5],[-2.0,3.0]])\n",
        "print(x)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.  -0.5]\n",
            " [-2.   3. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH7VdvvNh2IP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1012d9c5-8d27-4068-8de2-4ddb91d0e72a"
      },
      "source": [
        "mask = (x<=0)\n",
        "print(mask)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False  True]\n",
            " [ True False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14OfHOcviCEF",
        "colab_type": "text"
      },
      "source": [
        "mask 변수가 True/False로 구성된 넘파이 배열을 유지하는 것을 알 수 있다. \n",
        "\n",
        "ReLU 계층의 계산 그래프에서 순전파 때의 입력 값이 0 이하면 역전파 때의 값은 0이 되어야 하기 때문에 역전파 때는 순전파 때 만들어둔 mask를 써서 mask의 원소가 True인 곳에는 상류에서 전파된 dout을 0으로 설정한다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVogvJS6iqQr",
        "colab_type": "text"
      },
      "source": [
        "### **5.5.2 Sigmoid 계층**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIvHGD6GoD5s",
        "colab_type": "text"
      },
      "source": [
        "시드모이드 계층의 계산 그래프와 각 계산 단계는 교재 p.167-169 참고"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BLwszghh9eS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sigmoid:\n",
        "  def __init__(self):\n",
        "    self.out = None\n",
        "  \n",
        "  def forward(self,x):\n",
        "    out = 1 / (1+np.exp(-x))\n",
        "    self.out = out\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self,dout):\n",
        "    dx = dout*(1.0-self.out)*self.out\n",
        "\n",
        "    return dx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szrt5epSo-Pv",
        "colab_type": "text"
      },
      "source": [
        "Sigmoid 계층을 구현하였다. \n",
        "\n",
        "위의 구현에서는 순전파의 출력을 인스턴스 변수 out에 보관했다가, 역전파 계산 때 그 값을 사용했다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyPJLvBJpJp4",
        "colab_type": "text"
      },
      "source": [
        "## **5.6 Affine/Softmax 계층 구현하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUeoraK2pOqj",
        "colab_type": "text"
      },
      "source": [
        "### **5.6.1 Affine 계층**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q3jdhedo51k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.random.rand(2) #입력\n",
        "W = np.random.rand(2,3) #가중치\n",
        "B = np.random.rand(3) #편향"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcVFyMVzpmll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c2e4dbda-39c5-494f-b1d2-c71e63bc734c"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOLBx2hKpoLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "87a03337-dcf7-4fbf-f17a-89c5672a7cae"
      },
      "source": [
        "W.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nisbDCOippOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1cc1f9f6-c7f2-4687-cb41-8f525ff07f4d"
      },
      "source": [
        "B.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "todVo1PApp-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = np.dot(X,W) + B"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtQv4TZxpuve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "fe9575af-9622-41a9-975e-6b07ab4c216c"
      },
      "source": [
        "Y"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.34265424, 0.02930574, 0.38885983])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbE-2seKpzNF",
        "colab_type": "text"
      },
      "source": [
        "신경망의 순전파에서는 가중치 신호의 총합을 계산하기 때문에 위와 같이 행렬의 곱을 사용했었다. \n",
        "\n",
        "위의 Y를 활성화 함수로 변환해 다음 층으로 전파하는 것이 신경망 순전파의 흐름이었다. 또한 행렬의 곱 계산에서는 대응하는 차원의 원소 수를 일치시키는 것이 핵심이었다. \n",
        "\n",
        "행렬의 곱과 편향의 합을 계산 그래프로 나타내는 것은 교재 p.171-173 참고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPAZDa5wqtAi",
        "colab_type": "text"
      },
      "source": [
        "### **5.6.2 배치용 Affine 계층**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlitmsPWq3um",
        "colab_type": "text"
      },
      "source": [
        "지금까지 본 Affine 계층은 입력 데이터로 X 하나만을 고려한 것이었다. 이번 절에서 데이터 N개를 묶어 순전파하는 경우, 즉 배치용 Affine 계층을 생각해보겠다.\n",
        "\n",
        "교재 p.174의 배치용 Affine 계층의 계산 그래프를 확인해보면 X의 형상이 (N,2)로 변화한 것을 알 수 있다. 편향을 더할 때도 주의해주어야 한다. 순전파 때의 편향 덧셈은 X•W에 대한 편향이 각 데이터에 더해진다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8chmGU9ApvaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_dot_W = np.array([[0,0,0],[10,10,10]])\n",
        "B = np.array([1,2,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FX1-1V2rjYS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c0108625-c1e9-40e3-bd27-be940c0181f4"
      },
      "source": [
        "X_dot_W"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0],\n",
              "       [10, 10, 10]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ07kX0trk2Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "ce11a447-813e-4b6a-c4f1-3bdd80ddc8b2"
      },
      "source": [
        "X_dot_W + B"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  2,  3],\n",
              "       [11, 12, 13]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8VjtZGLrpbm",
        "colab_type": "text"
      },
      "source": [
        "순전파의 편향 덧셈이 각각의 데이터에 더해짐을 확인했다. 그래서 역전파 때는 각 데이터의 역전파 값이 편향의 원소에 모여야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBVJc5AlrmR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "04521981-371a-4e07-88fa-288c6bfd4e73"
      },
      "source": [
        "dY = np.array([[1,2,3],[4,5,6]])\n",
        "dY"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PndhmdgBr3pc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1e516108-2aa8-450d-864d-2d30a563ea0f"
      },
      "source": [
        "dB = np.sum(dY, axis=0)\n",
        "dB"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 7, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwAbgMU_r-jH",
        "colab_type": "text"
      },
      "source": [
        "역전파 값이 편향의 원소에 모이는 것을 코드로 보였다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8xY0bVKr7er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Affine:\n",
        "  def __init__(self,W,b):\n",
        "    self.W = W\n",
        "    self.b = b\n",
        "    self.x = None\n",
        "    self.dW = None\n",
        "    self.db = None\n",
        "\n",
        "  def forward(self,x):\n",
        "    self.x = x\n",
        "    out = np.dot(x,self.W)+self.b\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self,dout):\n",
        "    dx = np.dot(dout,self.W.T)\n",
        "    self.dW = np.dot(self.x.T,dout)\n",
        "    self.db = np.sum(dout,axis=0)\n",
        "\n",
        "    return dx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMue2K6IsljJ",
        "colab_type": "text"
      },
      "source": [
        "Affine을 구현했다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QlPWsbDt2UD",
        "colab_type": "text"
      },
      "source": [
        "### **Softmax-with-Loss 계층**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nChZDXsmulqq",
        "colab_type": "text"
      },
      "source": [
        "설명은 p.176-179 참고"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZwL01JIsjfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SoftmaxWithLoss:\n",
        "  def __init__(self):\n",
        "    self.loss = None #손실\n",
        "    self.y = None #softmax의 출력\n",
        "    self.t = None #정답 레이블(원-핫 벡터)\n",
        "\n",
        "  def forward(self,x,t):\n",
        "    self.t = t\n",
        "    self.y = softmax(x)\n",
        "    self.loss = cross_entropy_error(self.y,self.t)\n",
        "    return self.loss\n",
        "\n",
        "  def backward(self,dout=1):\n",
        "    batch_size = self.t.shape[0]\n",
        "    dx = (self.y-slef.t) / batch_size\n",
        "\n",
        "    return dx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxCvE5_LvHky",
        "colab_type": "text"
      },
      "source": [
        "Softmax-with-Loss 계층을 구현했다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8WKg1ayvLRu",
        "colab_type": "text"
      },
      "source": [
        "## **5.7 오차역전파법 구현하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxvMCAsjzVdY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "a8f4217e-30a4-4368-8c36-5c545b2a87c7"
      },
      "source": [
        "import sys,os\n",
        "sys.path.append(os.pardir)\n",
        "import numpy as np\n",
        "from common.layers import *\n",
        "from common.gradient import numerical_gradient\n",
        "from collections import OrderedDict\n",
        "\n",
        "class TwoLayerNet:\n",
        "  \n",
        "  def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
        "    # 가중치 초기화\n",
        "    self.params = {}\n",
        "    self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "    self.params['b1'] = np.zeros(hidden_size)\n",
        "    self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
        "    self.params['b2'] = np.zeros(output_size)\n",
        " \n",
        "    # 계층 생성\n",
        "    self.layers = OrderedDict() #신경망의 계층을 순서가 있는 딕셔너리에 보관한다.\n",
        "    self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
        "    self.layers['Relu1'] = Relu()\n",
        "    self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
        " \n",
        "    self.lastLayer = SoftmaxWithLoss()\n",
        "    \n",
        "    def predict(self, x):\n",
        "      for layer in self.layers.values():\n",
        "        x = layer.forward(x)\n",
        "        \n",
        "      return x\n",
        "\n",
        "    # x : 입력 데이터, t : 정답 레이블\n",
        "    def loss(self, x, t):\n",
        "      y = self.predict(x)\n",
        "      return self.lastLayer.forward(y, t)\n",
        "    \n",
        "    def accuracy(self, x, t):\n",
        "      y = self.predict(x)\n",
        "      y = np.argmax(y, axis=1)\n",
        "      if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
        "      \n",
        "      accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "      return accuracy\n",
        "    \n",
        "    # x : 입력 데이터, t : 정답 레이블\n",
        "    def numerical_gradient(self, x, t):\n",
        "      loss_W = lambda W: self.loss(x, t)\n",
        "      grads = {}\n",
        "      grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "      grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "      grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "      grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "      return grads\n",
        "    \n",
        "    def gradient(self, x, t):\n",
        "      # forward\n",
        "      self.loss(x, t)\n",
        " \n",
        "      # backward\n",
        "      dout = 1\n",
        "      dout = self.lastLayer.backward(dout)\n",
        " \n",
        "      layers = list(self.layers.values())\n",
        "      layers.reverse()\n",
        "      for layer in layers:\n",
        "        dout = layer.backward(dout)\n",
        " \n",
        "      # 결과 저장\n",
        "      grads = {}\n",
        "      grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
        "      grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
        " \n",
        "      return grads"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ec9d8fecdf13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpardir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3_kPySSySl1",
        "colab_type": "text"
      },
      "source": [
        "오차역전파법을 적용한 신경망을 구현했다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8knsS3HyZFw",
        "colab_type": "text"
      },
      "source": [
        "### **5.7.3 오차역전파법으로 구한 기울기 검증하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL7QxyQAxCo-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "d7c7d4fc-6f2a-4d10-e31c-35ab095f5257"
      },
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "from two_layer_net import TwoLayerNet\n",
        "\n",
        "# 데이터 읽기\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "x_batch = x_train[:3]\n",
        "t_batch = t_train[:3]\n",
        "\n",
        "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
        "grad_backprop = network.gradient(x_batch, t_batch)\n",
        "\n",
        "# 각 가중치의 절대 오차의 평균을 구한다.\n",
        "for key in grad_numerical.keys():\n",
        "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n",
        "    print(key + \":\" + str(diff))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2e46ae30addc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpardir\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 부모 디렉터리의 파일을 가져올 수 있도록 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtwo_layer_net\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTwoLayerNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataset'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OzhpH7Zz2j6",
        "colab_type": "text"
      },
      "source": [
        "기울기를 검증하는 코드를 구현했다.\n",
        "\n",
        "___\n",
        "\n",
        "기울기를 구하는 방법에는 수치 미분을 써서 구하는 방법과 해석적으로 수식을 풀어 구하는 방법이 있다. 후자인 해석적 방법은 오차역전파법을 이용하여 매개변수가 많아도 효율적으로 계산할 수 있었다.\n",
        "\n",
        "수치 미분은 느리지만 구협이 쉽고 버그가 숨어 있기 어렵기 때문에 오차역전파법을 정확히 구현했는지 확인하기 위해 필요하다. \n",
        "\n",
        "이처럼 두 방식으로 구한 기울기가 일치함을 확인하는 작업을 기울기 확인이라고 한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxaHXC2WziCz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "95b63d20-c7e7-4f2e-9333-14a4ddc45901"
      },
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "from two_layer_net import TwoLayerNet\n",
        "\n",
        "# 데이터 읽기\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "iters_num = 10000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "    \n",
        "    # 기울기 계산\n",
        "    #grad = network.numerical_gradient(x_batch, t_batch) # 수치 미분 방식\n",
        "    grad = network.gradient(x_batch, t_batch) # 오차역전파법 방식(훨씬 빠르다)\n",
        "    \n",
        "    # 갱신\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "    \n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "    \n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(train_acc, test_acc)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-59dcf162d87a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtwo_layer_net\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTwoLayerNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataset'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xPXJlD62mYR",
        "colab_type": "text"
      },
      "source": [
        "오차역전파법을 사용한 신경망 학습을 구현해보았다."
      ]
    }
  ]
}