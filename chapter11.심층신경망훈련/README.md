## chapter11. 심층신경망 훈련

## 1. 심층 신경망의 문제점
- 그래디언트 소실
- 그래디언트 폭주 
## 2. 해결방법(solution blog(필수) : https://wikidocs.net/61375)
- 가중치 초기화(세이비어, HE초기화)
- 수렴하지 않는 활성함수
- 배치 정규화
- 그래디언트 클리핑
## 3. 전이학습
## 4. 고속 옵티마이저 : 가장 빠르고 효율적으로 최적의 처리 경로를 생성
- 모멘텀 최적화 
- 네스테로프 가속 경사 
- AdaGrad
- RMSProp
- Adam최적화 
- 학습률 스케줄링 
## 5. 과대적합 문제의 해결 
- 조기종료
- l1, l2규제
- 드롭아웃 (논문 참고 : http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)
- 맥스-노름 규제
- 데이터 증식 : 하나의 데이터로 여러 학습 데이터를 생성하여 과대적합을 해결하는 방법 
## 6. 결론 
- 기본 DNN설정
    1. 초기화 : He초기화 
    2. 활성함수: ELU
    3. 정규화 : 배치 정규화 
    4. 규제 : 드롭아웃
    5. 옵티마이저 : 네스테로프 가속 경사
    6. 학습 스케줄링 : 없음
- 좋은 학습율을 찾을 수가 없다면 지수감소와 같은 학습 스케쥴 사용이 가능
- 훈련 데이터 셋이 작다면 데이터 증식 가능
- 희소모델이 필요하면 l1규제의 사용 
- 실행속도가 빠른 모델이 필요하면 ELU에서 LeakyReLU를 사용 


